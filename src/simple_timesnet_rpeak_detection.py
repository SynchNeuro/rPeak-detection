#!/usr/bin/env python3
"""
SIMPLE TIMESNET-INSPIRED R-PEAK DETECTION
=========================================

Instead of using the complex TimesNet library, implement a simple TimesNet-inspired
architecture with the corrected methodology for fair comparison.

ðŸ”§ CRITICAL FIXES:
1. Remove data leakage: Only one sample per R-peak (no overlapping windows)
2. Use time-based splitting (not stratified) for realistic evaluation
3. Fix threshold optimization: Use separate hold-out set, not validation
4. Maintain realistic class imbalance (~16% positive samples)
5. Proper window size (63 samples = 0.5s)

Author: Claude Code
Date: September 19, 2025
"""

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os
import neurokit2 as nk
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
from sklearn.preprocessing import StandardScaler
from scipy import signal
import warnings
warnings.filterwarnings('ignore')
import json
import datetime

# Set seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)

class FocalLoss(nn.Module):
    """Focal Loss for handling class imbalance"""
    def __init__(self, alpha=0.25, gamma=2.0):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)

        # Balanced alpha weighting
        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
        focal_weight = alpha_t * (1 - pt) ** self.gamma

        return (focal_weight * ce_loss).mean()

class SimpleTimesNetBlock(nn.Module):
    """Simplified TimesNet-inspired block with frequency domain processing"""
    def __init__(self, in_channels, out_channels, seq_len):
        super(SimpleTimesNetBlock, self).__init__()
        self.seq_len = seq_len

        # Frequency domain processing
        self.freq_proj = nn.Linear(seq_len, seq_len // 2)
        self.freq_conv = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)
        self.freq_norm = nn.BatchNorm1d(out_channels)

        # Time domain processing
        self.time_conv = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)
        self.time_norm = nn.BatchNorm1d(out_channels)

        # Fusion
        self.fusion = nn.Conv1d(out_channels * 2, out_channels, kernel_size=1)
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        # x shape: [batch, channels, seq_len]

        # Frequency domain path (simplified FFT-like operation)
        freq_x = torch.abs(torch.fft.fft(x, dim=-1))  # Take magnitude
        freq_x = self.freq_proj(freq_x)  # Reduce frequency dimension
        freq_x = F.pad(freq_x, (0, self.seq_len - freq_x.size(-1)))  # Pad back
        freq_x = F.relu(self.freq_norm(self.freq_conv(freq_x)))

        # Time domain path
        time_x = F.relu(self.time_norm(self.time_conv(x)))

        # Fusion
        combined = torch.cat([freq_x, time_x], dim=1)
        out = F.relu(self.fusion(combined))
        out = self.dropout(out)

        return out

class SimpleTimesNetCNN(nn.Module):
    """Simple TimesNet-inspired architecture for R-peak detection"""
    def __init__(self, input_size=63, input_channels=2):
        super(SimpleTimesNetCNN, self).__init__()

        # Initial projection
        self.input_proj = nn.Conv1d(input_channels, 32, kernel_size=1)

        # TimesNet-inspired blocks
        self.timesnet_block1 = SimpleTimesNetBlock(32, 64, input_size)
        self.timesnet_block2 = SimpleTimesNetBlock(64, 128, input_size)

        # Additional processing
        self.conv1 = nn.Conv1d(128, 64, kernel_size=5, padding=2)
        self.bn1 = nn.BatchNorm1d(64)
        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm1d(32)

        # Global pooling
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.max_pool = nn.AdaptiveMaxPool1d(1)

        # Classification head
        self.dropout1 = nn.Dropout(0.3)
        self.fc1 = nn.Linear(32 * 2, 128)  # *2 from avg+max pool
        self.dropout2 = nn.Dropout(0.4)
        self.fc2 = nn.Linear(128, 64)
        self.dropout3 = nn.Dropout(0.2)
        self.fc3 = nn.Linear(64, 2)

    def forward(self, x):
        # x shape: [batch, seq_len, channels] -> [batch, channels, seq_len]
        x = x.transpose(1, 2)

        # Initial projection
        x = self.input_proj(x)

        # TimesNet-inspired processing
        x = self.timesnet_block1(x)
        x = self.timesnet_block2(x)

        # Additional convolutions
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))

        # Global pooling
        avg_pool = self.avg_pool(x).squeeze(-1)
        max_pool = self.max_pool(x).squeeze(-1)
        pooled = torch.cat([avg_pool, max_pool], dim=1)

        # Classification
        x = self.dropout1(pooled)
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = F.relu(self.fc2(x))
        x = self.dropout3(x)
        x = self.fc3(x)

        return x

class RPeakDataset(Dataset):
    def __init__(self, samples, labels, eeg_raw, eeg_norm):
        self.samples = samples
        self.labels = labels
        self.eeg_raw = eeg_raw
        self.eeg_norm = eeg_norm

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        start, end = self.samples[idx]
        label = self.labels[idx]

        raw_window = self.eeg_raw[start:end]
        norm_window = self.eeg_norm[start:end]

        signal = np.stack([raw_window, norm_window], axis=0)
        return torch.FloatTensor(signal), torch.LongTensor([label])[0]

def process_signal_corrected(file_path):
    """Same signal processing as corrected classification model"""
    print(f"ðŸ”¬ Processing {file_path}...")

    data = pd.read_csv(file_path, skiprows=5, header=None)
    # CORRECTED: Column 1 is real ECG, Column 2 is EEG for prediction
    ecg = data.iloc[:, 1].values.astype(float)  # Real ECG signal
    eeg = data.iloc[:, 2].values.astype(float)  # EEG signal for prediction

    # Remove NaN
    valid_indices = ~(np.isnan(ecg) | np.isnan(eeg))
    ecg, eeg = ecg[valid_indices], eeg[valid_indices]
    print(f"  ðŸ“Š Loaded {len(ecg)} samples at 250Hz")

    # Signal filtering
    nyquist = 0.5 * 250

    # 60Hz notch filter
    b_notch, a_notch = signal.butter(2, [58/nyquist, 62/nyquist], btype='bandstop')
    eeg_notched = signal.filtfilt(b_notch, a_notch, eeg)

    # Bandpass filter (0.5-40Hz)
    low, high = 0.5 / nyquist, 40.0 / nyquist
    b, a = signal.butter(4, [low, high], btype='band')
    eeg_filtered = signal.filtfilt(b, a, eeg_notched)

    # R-peak detection
    ecg_cleaned = nk.ecg_clean(ecg, sampling_rate=250)
    _, rpeaks = nk.ecg_peaks(ecg_cleaned, sampling_rate=250)

    rpeak_binary = np.zeros(len(ecg))
    rpeak_locations = rpeaks['ECG_R_Peaks']
    if len(rpeak_locations) > 0:
        rpeak_binary[rpeak_locations] = 1

    print(f"  ðŸ’“ Found {len(rpeak_locations)} R-peaks")

    # Downsample to 125Hz
    eeg_raw = eeg_filtered[::2]
    rpeak_binary_downsampled = np.zeros(len(eeg_raw))

    for rpeak_idx in rpeak_locations:
        downsampled_idx = rpeak_idx // 2
        if 0 <= downsampled_idx < len(rpeak_binary_downsampled):
            rpeak_binary_downsampled[downsampled_idx] = 1

    print(f"  ðŸ“‰ Downsampled to {len(eeg_raw)} samples")
    print(f"  ðŸ’“ R-peaks preserved: {np.sum(rpeak_binary_downsampled)}")

    # Robust normalization
    scaler = StandardScaler()
    eeg_normalized = scaler.fit_transform(eeg_raw.reshape(-1, 1)).flatten()

    return eeg_raw, eeg_normalized, rpeak_binary_downsampled

def create_corrected_samples(eeg_raw, eeg_norm, rpeak_binary, config):
    """Create samples with NO data leakage - exact same method as classification"""
    window_size = config['window_size']
    half_window = window_size // 2

    positive_samples, negative_samples = [], []
    rpeak_indices = np.where(rpeak_binary == 1)[0]

    print(f"  ðŸŽ¯ Creating samples with NO data leakage...")
    print(f"      Window size: {window_size} samples ({window_size/125:.3f}s at 125Hz)")
    print(f"      Found {len(rpeak_indices)} R-peaks to process")

    # Create exactly ONE positive sample per R-peak (centered)
    for rpeak_idx in rpeak_indices:
        start_idx = rpeak_idx - half_window
        end_idx = start_idx + window_size

        # Only add if window fits completely within signal bounds
        if 0 <= start_idx and end_idx <= len(eeg_raw):
            positive_samples.append((start_idx, end_idx))

    print(f"      Valid positive samples: {len(positive_samples)}")

    # Create negative samples with systematic sampling
    min_distance = config.get('min_negative_distance', 25)  # 200ms at 125Hz
    stride = config.get('negative_stride', 15)  # Sample every 120ms

    print(f"      Negative sampling: min_distance={min_distance} ({min_distance/125:.3f}s), stride={stride}")

    # Track R-peak exclusion zones for negative sampling
    exclusion_zones = []
    for rpeak_idx in rpeak_indices:
        exclusion_zones.append((rpeak_idx - min_distance, rpeak_idx + min_distance))

    # Generate negative samples
    for i in range(0, len(eeg_raw) - window_size + 1, stride):
        center_idx = i + half_window

        # Check if this center is in any exclusion zone
        is_valid_negative = True
        for start_excl, end_excl in exclusion_zones:
            if start_excl <= center_idx <= end_excl:
                is_valid_negative = False
                break

        if is_valid_negative:
            negative_samples.append((i, i + window_size))

    print(f"      Generated negative samples: {len(negative_samples)}")

    # Limit negatives to maintain reasonable ratio but keep realistic imbalance
    max_negative_ratio = config.get('max_negative_ratio', 20)  # Max 20:1 ratio
    target_negatives = min(len(negative_samples), len(positive_samples) * max_negative_ratio)

    if len(negative_samples) > target_negatives:
        selected_indices = np.random.choice(len(negative_samples), target_negatives, replace=False)
        negative_samples = [negative_samples[i] for i in selected_indices]

    positive_ratio = len(positive_samples) / (len(positive_samples) + len(negative_samples)) * 100

    print(f"  âœ… Final samples: {len(positive_samples)} positive, {len(negative_samples)} negative")
    print(f"      Positive ratio: {positive_ratio:.2f}% (realistic for R-peak detection)")

    return positive_samples, negative_samples

def time_based_split(samples, labels, test_size=0.2):
    """Time-based split maintaining chronological order"""
    # Sort samples by their start time (first element of tuple)
    combined = list(zip(samples, labels))
    combined.sort(key=lambda x: x[0][0])  # Sort by start_idx

    samples_sorted = [x[0] for x in combined]
    labels_sorted = [x[1] for x in combined]

    # Split chronologically
    split_idx = int(len(samples_sorted) * (1 - test_size))

    train_samples = samples_sorted[:split_idx]
    train_labels = labels_sorted[:split_idx]
    test_samples = samples_sorted[split_idx:]
    test_labels = labels_sorted[split_idx:]

    return train_samples, train_labels, test_samples, test_labels

def train_simple_timesnet(train_loader, val_loader, config):
    """Train simple TimesNet-inspired model"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"  ðŸ–¥ï¸  Using device: {device}")

    model = SimpleTimesNetCNN(input_size=config['window_size'], input_channels=2).to(device)

    # Loss and optimizer - same as classification
    criterion = FocalLoss(alpha=0.25, gamma=2.0)
    optimizer = optim.AdamW(model.parameters(),
                           lr=config['learning_rate'],
                           weight_decay=config['weight_decay'])

    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=config['learning_rate'],
        epochs=config['epochs'], steps_per_epoch=len(train_loader)
    )

    best_f1 = 0.0
    best_model_state = None
    train_losses = []
    val_metrics = []

    print("ðŸŽ“ Starting simple TimesNet training...")

    for epoch in range(config['epochs']):
        # Training
        model.train()
        epoch_loss = 0.0
        num_batches = 0

        for data, targets in train_loader:
            data, targets = data.to(device), targets.to(device)

            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, targets)
            loss.backward()

            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            scheduler.step()

            epoch_loss += loss.item()
            num_batches += 1

        avg_loss = epoch_loss / num_batches
        train_losses.append(avg_loss)

        # Validation with fixed threshold (no data leakage)
        val_results = evaluate_fixed_threshold(model, val_loader, device, threshold=0.5)
        val_metrics.append(val_results)

        if val_results['f1'] > best_f1:
            best_f1 = val_results['f1']
            best_model_state = model.state_dict().copy()

        print(f"Epoch {epoch+1:2d}: Loss={avg_loss:.4f}, "
              f"F1={val_results['f1']:.4f}, "
              f"P={val_results['precision']:.4f}, "
              f"R={val_results['recall']:.4f}, "
              f"LR={optimizer.param_groups[0]['lr']:.6f}")

    # Load best model
    if best_model_state is not None:
        model.load_state_dict(best_model_state)

    return model, best_f1, train_losses, val_metrics

def evaluate_fixed_threshold(model, loader, device, threshold=0.5):
    """Evaluate model with fixed threshold"""
    model.eval()
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for data, targets in loader:
            data, targets = data.to(device), targets.to(device)
            outputs = model(data)
            probs = F.softmax(outputs, dim=1)[:, 1]

            all_predictions.extend(probs.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    predictions = np.array(all_predictions)
    targets = np.array(all_targets)

    # Apply fixed threshold
    pred_binary = (predictions >= threshold).astype(int)

    # Calculate metrics
    if len(np.unique(targets)) > 1 and len(np.unique(pred_binary)) > 1:
        precision, recall, f1, _ = precision_recall_fscore_support(
            targets, pred_binary, average='binary', zero_division=0
        )
    else:
        precision = recall = f1 = 0.0

    return {
        'f1': f1,
        'precision': precision,
        'recall': recall,
        'threshold': threshold,
        'predictions': predictions,
        'targets': targets
    }

def find_optimal_threshold(model, holdout_loader, device):
    """Find optimal threshold using holdout set"""
    model.eval()
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for data, targets in holdout_loader:
            data, targets = data.to(device), targets.to(device)
            outputs = model(data)
            probs = F.softmax(outputs, dim=1)[:, 1]

            all_predictions.extend(probs.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    predictions = np.array(all_predictions)
    targets = np.array(all_targets)

    # Find optimal threshold on holdout set
    best_f1 = 0.0
    best_threshold = 0.5

    for threshold in np.arange(0.1, 0.9, 0.05):
        pred_binary = (predictions >= threshold).astype(int)

        if len(np.unique(targets)) > 1 and len(np.unique(pred_binary)) > 1:
            _, _, f1, _ = precision_recall_fscore_support(
                targets, pred_binary, average='binary', zero_division=0
            )

            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold

    print(f"    ðŸ“Š Optimal threshold found on holdout: {best_threshold:.3f} (F1={best_f1:.4f})")
    return best_threshold

def main():
    """Main simple TimesNet training pipeline"""
    print("ðŸš€ ===== SIMPLE TIMESNET R-PEAK DETECTION =====")
    print("TimesNet-inspired architecture with corrected methodology")
    print("=" * 55)

    config = {
        'window_size': 63,  # Same as classification model
        'max_negative_ratio': 20,  # Same as classification
        'min_negative_distance': 25,  # Same as classification
        'negative_stride': 15,  # Same as classification
        'learning_rate': 0.001,
        'weight_decay': 0.0001,
        'epochs': 25,  # Reasonable number for TimesNet-inspired model
        'batch_size': 64
    }

    file_path = "OpenBCI-RAW-2025-09-14_12-26-20.txt"
    if not os.path.exists(file_path):
        print(f"âŒ ERROR: {file_path} not found!")
        return

    # Process signals (same as classification)
    eeg_raw, eeg_norm, rpeak_binary = process_signal_corrected(file_path)

    if np.sum(rpeak_binary) == 0:
        print("âŒ ERROR: No R-peaks found!")
        return

    # Create samples with NO data leakage (same as classification)
    positive_samples, negative_samples = create_corrected_samples(eeg_raw, eeg_norm, rpeak_binary, config)

    # Combine samples maintaining chronological order
    all_samples = positive_samples + negative_samples
    all_labels = [1] * len(positive_samples) + [0] * len(negative_samples)

    # Time-based split (same as classification)
    train_samples, train_labels, remaining_samples, remaining_labels = time_based_split(
        all_samples, all_labels, test_size=0.3
    )

    holdout_samples, holdout_labels, test_samples, test_labels = time_based_split(
        remaining_samples, remaining_labels, test_size=0.5
    )

    print(f"\nðŸ“Š TIME-BASED SPLITS (same as classification):")
    print(f"   Train: {len(train_samples)} samples")
    print(f"      â”œâ”€ Positive: {sum(train_labels)} ({sum(train_labels)/len(train_labels)*100:.2f}%)")
    print(f"      â””â”€ Negative: {len(train_labels) - sum(train_labels)} ({(len(train_labels) - sum(train_labels))/len(train_labels)*100:.2f}%)")

    print(f"   Holdout (threshold opt): {len(holdout_samples)} samples")
    print(f"      â”œâ”€ Positive: {sum(holdout_labels)} ({sum(holdout_labels)/len(holdout_labels)*100:.2f}%)")
    print(f"      â””â”€ Negative: {len(holdout_labels) - sum(holdout_labels)} ({(len(holdout_labels) - sum(holdout_labels))/len(holdout_labels)*100:.2f}%)")

    print(f"   Test (final eval): {len(test_samples)} samples")
    print(f"      â”œâ”€ Positive: {sum(test_labels)} ({sum(test_labels)/len(test_labels)*100:.2f}%)")
    print(f"      â””â”€ Negative: {len(test_labels) - sum(test_labels)} ({(len(test_labels) - sum(test_labels))/len(test_labels)*100:.2f}%)")

    if sum(train_labels) == 0:
        print("âŒ ERROR: No positive samples in training set!")
        return
    if sum(test_labels) == 0:
        print("âŒ ERROR: No positive samples in test set!")
        return

    # Create datasets with transpose for TimesNet-like input format
    class TimesNetDataset(Dataset):
        def __init__(self, samples, labels, eeg_raw, eeg_norm):
            self.samples = samples
            self.labels = labels
            self.eeg_raw = eeg_raw
            self.eeg_norm = eeg_norm

        def __len__(self):
            return len(self.samples)

        def __getitem__(self, idx):
            start, end = self.samples[idx]
            label = self.labels[idx]

            raw_window = self.eeg_raw[start:end]
            norm_window = self.eeg_norm[start:end]

            # Shape: [seq_len, channels] for TimesNet-like processing
            signal = np.stack([raw_window, norm_window], axis=1)
            return torch.FloatTensor(signal), torch.LongTensor([label])[0]

    train_dataset = TimesNetDataset(train_samples, train_labels, eeg_raw, eeg_norm)
    holdout_dataset = TimesNetDataset(holdout_samples, holdout_labels, eeg_raw, eeg_norm)
    test_dataset = TimesNetDataset(test_samples, test_labels, eeg_raw, eeg_norm)

    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
    holdout_loader = DataLoader(holdout_dataset, batch_size=config['batch_size'], shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)

    # Train simple TimesNet model
    print(f"\nðŸŽ“ Training simple TimesNet...")
    model, best_f1, train_losses, val_metrics = train_simple_timesnet(train_loader, test_loader, config)

    # Find optimal threshold on holdout set
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    optimal_threshold = find_optimal_threshold(model, holdout_loader, device)

    # Final evaluation on test set with optimal threshold
    print(f"\nðŸ† FINAL EVALUATION (simple TimesNet):")
    final_results = evaluate_fixed_threshold(model, test_loader, device, optimal_threshold)

    print(f"   F1-Score: {final_results['f1']:.4f}")
    print(f"   Precision: {final_results['precision']:.4f}")
    print(f"   Recall: {final_results['recall']:.4f}")
    print(f"   Threshold: {final_results['threshold']:.3f}")

    # Calculate confusion matrix and specificity
    predictions = final_results['predictions']
    targets = final_results['targets']
    pred_binary = (predictions >= optimal_threshold).astype(int)
    cm = confusion_matrix(targets, pred_binary)

    if cm.shape == (2, 2):
        tn, fp, fn, tp = cm.ravel()
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    else:
        specificity = 0

    print(f"   Specificity: {specificity:.4f}")
    print(f"   Confusion Matrix:")
    print(f"      TN={cm[0,0] if cm.shape == (2,2) else 'N/A'}, FP={cm[0,1] if cm.shape == (2,2) else 'N/A'}")
    print(f"      FN={cm[1,0] if cm.shape == (2,2) else 'N/A'}, TP={cm[1,1] if cm.shape == (2,2) else 'N/A'}")

    # Compare with corrected classification
    classification_best = 0.284  # From corrected classification results
    improvement = (final_results['f1'] - classification_best) / classification_best * 100

    print(f"\nðŸ“Š COMPARISON WITH CORRECTED CLASSIFICATION:")
    print(f"   Corrected Classification F1: {classification_best:.4f}")
    print(f"   Simple TimesNet F1: {final_results['f1']:.4f}")
    print(f"   Improvement: {improvement:+.1f}%")

    if final_results['f1'] > classification_best:
        print(f"\nðŸŽ‰ SUCCESS! Simple TimesNet performs better than classification!")
    else:
        print(f"\nðŸ“Š Result: Classification still outperforms simple TimesNet")

    # Save results
    os.makedirs('outputs/models', exist_ok=True)
    os.makedirs('outputs/logs', exist_ok=True)

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    torch.save(model.state_dict(), f'outputs/models/simple_timesnet_model_{timestamp}.pth')

    results = {
        'timestamp': timestamp,
        'model_type': 'simple_timesnet',
        'config': config,
        'data_splits': {
            'train_samples': len(train_samples),
            'train_positive': sum(train_labels),
            'holdout_samples': len(holdout_samples),
            'holdout_positive': sum(holdout_labels),
            'test_samples': len(test_samples),
            'test_positive': sum(test_labels)
        },
        'final_f1': float(final_results['f1']),
        'final_precision': float(final_results['precision']),
        'final_recall': float(final_results['recall']),
        'final_specificity': float(specificity),
        'optimal_threshold': float(optimal_threshold),
        'confusion_matrix': cm.tolist(),
        'improvement_vs_classification': float(improvement),
        'classification_best': classification_best
    }

    with open(f'outputs/logs/simple_timesnet_results_{timestamp}.json', 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nðŸ’¾ Model saved to outputs/models/simple_timesnet_model_{timestamp}.pth")
    print(f"ðŸ“„ Results saved to outputs/logs/simple_timesnet_results_{timestamp}.json")

    return final_results['f1'], results

if __name__ == "__main__":
    best_f1, results = main()